version: "3.9"

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      - PORT=8001
      - SPRING_AI_OLLAMA_BASE_URL=http://llama3:11434/
    depends_on:
      - llama3

  llama3:
    build:
      context: .
      dockerfile: Dockerfile.llama3
    ports:
      - "11434:11434"
    volumes:
      - ./llama_models:/root/.ollama/models
